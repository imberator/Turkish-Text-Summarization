{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "14410483",
      "metadata": {
        "id": "14410483"
      },
      "source": [
        "# Hugging Face - Summarization in Turkish\n",
        "\n",
        "This source code builds the fine-tuned model of [google/mt5-small](https://huggingface.co/google/mt5-small) for Turkish summarization.\n",
        "\n",
        "For more background and details, see [this blog post](https://tsmatz.wordpress.com/2022/11/25/huggingface-japanese-summarization/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FgQoSyQkf4Ki",
      "metadata": {
        "id": "FgQoSyQkf4Ki"
      },
      "outputs": [],
      "source": [
        "# Mount drive since this notebook is organized to be used in colab environment.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab3bf825",
      "metadata": {
        "id": "ab3bf825"
      },
      "source": [
        "Install packages depending on T5 tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12a86426",
      "metadata": {
        "id": "12a86426"
      },
      "outputs": [],
      "source": [
        "!pip install protobuf==3.20.3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4b66d94",
      "metadata": {
        "id": "d4b66d94"
      },
      "source": [
        "Install packages depending on rouge evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aee740d4",
      "metadata": {
        "id": "aee740d4"
      },
      "outputs": [],
      "source": [
        "!pip install absl-py rouge_score nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c04ef40e",
      "metadata": {
        "id": "c04ef40e"
      },
      "source": [
        "## Check device\n",
        "\n",
        "Check whether GPU is available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5bc098b",
      "metadata": {
        "id": "f5bc098b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is enabled.\")\n",
        "    print(\"device count: {}, current device: {}\".format(torch.cuda.device_count(), torch.cuda.current_device()))\n",
        "else:\n",
        "    print(\"GPU is not enabled.\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5163ab77",
      "metadata": {
        "id": "5163ab77"
      },
      "source": [
        "## Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rgZCxl6mWr68",
      "metadata": {
        "id": "rgZCxl6mWr68"
      },
      "outputs": [],
      "source": [
        "!pip3 install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are various datasets for Turkish text summarization. Based on the results of [1], I chose TR-News dataset.\n",
        "\n",
        "[1] B. Baykara and T. Güngör, \"Turkish abstractive text summarization using pretrained sequence-to-sequence models,\" Cambridge University Press, 2022."
      ],
      "metadata": {
        "id": "onBhFsALOFk4"
      },
      "id": "onBhFsALOFk4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20a1866b",
      "metadata": {
        "id": "20a1866b"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "#\n",
        "# I chose\n",
        "#ds = load_dataset(\"csebuetnlp/xlsum\", name=\"turkish\")\n",
        "#ds = load_dataset(\"mlsum\", \"tu\")\n",
        "ds = load_dataset(\"batubayk/TR-News\")\n",
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8da181d",
      "metadata": {
        "id": "c8da181d"
      },
      "outputs": [],
      "source": [
        "ds[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c42045d0",
      "metadata": {
        "id": "c42045d0"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "t5_tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "692dd056",
      "metadata": {
        "id": "692dd056"
      },
      "source": [
        "## Fine-tune"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd8231f7",
      "metadata": {
        "id": "bd8231f7"
      },
      "source": [
        "For fine-tuning, apply tokenization for dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m97aGCj-_7TP",
      "metadata": {
        "id": "m97aGCj-_7TP"
      },
      "outputs": [],
      "source": [
        "def tokenize_sample_data(data):\n",
        "  input_feature = t5_tokenizer(data[\"content\"], truncation=True, max_length=1024)\n",
        "  label = t5_tokenizer(data[\"abstract\"], truncation=True, max_length=128)\n",
        "  return {\n",
        "    \"input_ids\": input_feature[\"input_ids\"],\n",
        "    \"attention_mask\": input_feature[\"attention_mask\"],\n",
        "    \"labels\": label[\"input_ids\"],\n",
        "  }\n",
        "\n",
        "tokenized_ds = ds.map(\n",
        "  tokenize_sample_data,\n",
        "  remove_columns=[\"abstract\", \"author\", \"content\", \"date\", \"source\", \"tags\", \"title\", \"topic\", \"url\"],\n",
        "  batched=True,\n",
        "  batch_size=128)\n",
        "\n",
        "tokenized_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39cab1c7",
      "metadata": {
        "id": "39cab1c7"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoConfig, AutoModelForSeq2SeqLM\n",
        "\n",
        "mt5_config = AutoConfig.from_pretrained(\n",
        "    \"google/mt5-small\",\n",
        "    max_length=128,\n",
        "    length_penalty=0.6,\n",
        "    no_repeat_ngram_size=2,\n",
        "    num_beams=15,\n",
        ")\n",
        "model = (AutoModelForSeq2SeqLM\n",
        "         .from_pretrained(\"google/mt5-small\", config=mt5_config)\n",
        "         .to(device))\n",
        "\n",
        "# To avoid ValueErros caused by possible non-contiguous tensors.\n",
        "for param in model.parameters():\n",
        "    param.data = param.data.contiguous()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc213f22",
      "metadata": {
        "id": "bc213f22"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    t5_tokenizer,\n",
        "    model=model,\n",
        "    return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WgegtbwYXwAg",
      "metadata": {
        "id": "WgegtbwYXwAg"
      },
      "outputs": [],
      "source": [
        "!pip3 install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5dd0da9",
      "metadata": {
        "id": "f5dd0da9"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "rouge_metric = evaluate.load(\"rouge\")\n",
        "\n",
        "def tokenize_sentence(arg):\n",
        "    encoded_arg = t5_tokenizer(arg)\n",
        "    return t5_tokenizer.convert_ids_to_tokens(encoded_arg.input_ids)\n",
        "\n",
        "def metrics_func(eval_arg):\n",
        "    preds, labels = eval_arg\n",
        "    # Replace -100\n",
        "    labels = np.where(labels != -100, labels, t5_tokenizer.pad_token_id)\n",
        "    # Convert id tokens to text\n",
        "    text_preds = t5_tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    text_labels = t5_tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    # Insert a line break (\\n) in each sentence for ROUGE scoring\n",
        "    # (Note : Please change this code, when you perform on other languages)\n",
        "    text_preds = [(p if p.endswith((\"!\", \"?\", \".\")) else p + \".\") for p in text_preds]\n",
        "    text_labels = [(l if l.endswith((\"!\", \"?\", \".\")) else l + \".\") for l in text_labels]\n",
        "    sent_tokenizer_tr = RegexpTokenizer(u'[^!?.]*[!?.]')\n",
        "    text_preds = [\"\\n\".join(np.char.strip(sent_tokenizer_tr.tokenize(p))) for p in text_preds]\n",
        "    text_labels = [\"\\n\".join(np.char.strip(sent_tokenizer_tr.tokenize(l))) for l in text_labels]\n",
        "    # compute ROUGE score with custom tokenization\n",
        "    return rouge_metric.compute(\n",
        "        predictions=text_preds,\n",
        "        references=text_labels,\n",
        "        tokenizer=tokenize_sentence\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5e99037",
      "metadata": {
        "id": "a5e99037"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "sample_dataloader = DataLoader(\n",
        "    tokenized_ds[\"test\"].with_format(\"torch\"),\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=5)\n",
        "for batch in sample_dataloader:\n",
        "    with torch.no_grad():\n",
        "        preds = model.generate(\n",
        "            batch[\"input_ids\"].to(device),\n",
        "            num_beams=15,\n",
        "            num_return_sequences=1,\n",
        "            no_repeat_ngram_size=1,\n",
        "            remove_invalid_values=True,\n",
        "            max_length=128,\n",
        "        )\n",
        "    labels = batch[\"labels\"]\n",
        "    break\n",
        "\n",
        "metrics_func([preds, labels])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78f28731",
      "metadata": {
        "id": "78f28731"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "# \"save_steps\" and \"save_total_limit\" parameters\n",
        "# can be chosen arbitrarily based on the memory constraints\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir = \"mt5-summarize-tr-trnews\",\n",
        "    log_level = \"error\",\n",
        "    num_train_epochs = 10,\n",
        "    learning_rate = 5e-4,\n",
        "    lr_scheduler_type = \"linear\",\n",
        "    warmup_steps = 90,\n",
        "    optim = \"adafactor\",\n",
        "    weight_decay = 0.01,\n",
        "    per_device_train_batch_size = 2,\n",
        "    per_device_eval_batch_size = 1,\n",
        "    gradient_accumulation_steps = 16,\n",
        "    evaluation_strategy = \"steps\",\n",
        "    eval_steps = 100,\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length = 128,\n",
        "    save_steps = 500,\n",
        "    logging_steps = 10,\n",
        "    push_to_hub = False,\n",
        "    save_total_limit=3\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3978f071",
      "metadata": {
        "id": "3978f071"
      },
      "source": [
        "Build trainer. (Put it all together.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bca8a572",
      "metadata": {
        "id": "bca8a572"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    data_collator = data_collator,\n",
        "    compute_metrics = metrics_func,\n",
        "    train_dataset = tokenized_ds[\"train\"],\n",
        "    eval_dataset = tokenized_ds[\"validation\"].select(range(20)),\n",
        "    tokenizer = t5_tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce8b530f",
      "metadata": {
        "id": "ce8b530f"
      },
      "source": [
        "Run training.<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a66059ec",
      "metadata": {
        "id": "a66059ec"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ca6f566",
      "metadata": {
        "id": "5ca6f566"
      },
      "source": [
        "## Generate Text (Summarize) with Fine-Tuned Model\n",
        "\n",
        "Now let's see how it generates text for summarization with fine-tuned model.<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44578fb6",
      "metadata": {
        "id": "44578fb6"
      },
      "source": [
        "In order to use it later, you can save the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0710012a",
      "metadata": {
        "id": "0710012a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "save_directory = \"path/to/save\"\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "\n",
        "if hasattr(trainer.model, \"module\"):\n",
        "    trainer.model.module.save_pretrained(save_directory)\n",
        "else:\n",
        "    trainer.model.save_pretrained(save_directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf2efe66",
      "metadata": {
        "id": "bf2efe66"
      },
      "source": [
        "Load pre-trained model from local."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2be7c430",
      "metadata": {
        "id": "2be7c430"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "model = (AutoModelForSeq2SeqLM\n",
        "         .from_pretrained(\"./path\")\n",
        "         .to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ca11263",
      "metadata": {
        "id": "4ca11263"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Predict with test data (first 5 rows)\n",
        "sample_dataloader = DataLoader(\n",
        "    tokenized_ds[\"test\"].with_format(\"torch\"),\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=5)\n",
        "for batch in sample_dataloader:\n",
        "    with torch.no_grad():\n",
        "        preds = model.generate(\n",
        "            batch[\"input_ids\"].to(device),\n",
        "            num_beams=15,\n",
        "            num_return_sequences=1,\n",
        "            no_repeat_ngram_size=1,\n",
        "            remove_invalid_values=True,\n",
        "            max_length=128,\n",
        "        )\n",
        "    labels = batch[\"labels\"]\n",
        "    break\n",
        "\n",
        "labels = np.where(labels != -100, labels, t5_tokenizer.pad_token_id)\n",
        "\n",
        "# Convert id tokens to text\n",
        "text_preds = t5_tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "text_labels = t5_tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "# Show result\n",
        "print(\"***** Input's Text *****\")\n",
        "print(ds[\"test\"][\"text\"][0])\n",
        "print(\"***** Summary Text (True Value) *****\")\n",
        "print(text_labels[0])\n",
        "print(\"***** Summary Text (Generated Text) *****\")\n",
        "print(text_preds[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4da2045",
      "metadata": {
        "id": "a4da2045"
      },
      "outputs": [],
      "source": [
        "print(\"***** Input's Text *****\")\n",
        "print(ds[\"test\"][\"text\"][2])\n",
        "print(\"***** Summary Text (True Value) *****\")\n",
        "print(text_labels[2])\n",
        "print(\"***** Summary Text (Generated Text) *****\")\n",
        "print(text_preds[2])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}